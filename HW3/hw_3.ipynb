{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893682cc",
   "metadata": {},
   "source": [
    "# Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91221a",
   "metadata": {},
   "source": [
    "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются.\n",
    "\n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена.\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам “Война и мир” по-русски и по-английски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4293046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_AnnaKarenina = \"data/AnnaKarenina.txt\"\n",
    "path_to_WarAndPeace = \"data/WarAndPeace.txt\"\n",
    "path_to_WarAndPeaceEng = \"data/WarAndPeaceEng.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee774e",
   "metadata": {},
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c23393",
   "metadata": {},
   "source": [
    "1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "    * подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "    * возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "    * расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ea4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9407606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support function\n",
    "\n",
    "def read_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "        data = file.read().replace('\\n', ' ')\n",
    "        data = re.sub('\\W+',' ', data).lower()\n",
    "    return data\n",
    "\n",
    "def show_first_elem(d, i):\n",
    "    cnt = 0\n",
    "    for k, v in d:\n",
    "        cnt+=1\n",
    "        print(f'\\\"{k}\\\" :  {v}')\n",
    "        if cnt == i:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36857a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnnaKarenina = read_data(path_to_AnnaKarenina)\n",
    "WarAndPeace = read_data(path_to_WarAndPeace)\n",
    "WarAndPeaceEng = read_data(path_to_WarAndPeaceEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6c5ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть перваяi лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях 61 100 1 в 70 е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобное 2 ф м достоевский находил в новом романе толстого огромную психологическую разработку души человеческой страшную глубину и силу и главное небывалый доселе у нас реализм художественного изображения 3 время подтвердило эту высокую оценку из статей и книг на всех языках мира посвященных анне карениной можно составить целую библиотеку я без колебаний назвал анну каренину величайшим социальным романом во всей мировой литературе 4 писал томас манн значение романа толстого состоит не в эстетической '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b5327",
   "metadata": {},
   "source": [
    "Возьмем из Анны Карениной тестовые тексты это будут 500, 1000 и 2000 первых символов и в качестве бонуса на всем сете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91358c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encoder(text):\n",
    "    \n",
    "    chars_in_text = list(set(text))\n",
    "    \n",
    "    cipher = list(set(string.printable))\n",
    "    random.shuffle(cipher)\n",
    "    cipher = cipher[:len(chars_in_text)]\n",
    "    mapping = dict(zip(chars_in_text, cipher)) \n",
    "    ciphertext = [mapping[char] for char in text]\n",
    "    \n",
    "    return \"\".join(ciphertext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad84dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = AnnaKarenina[:500]\n",
    "text2 = AnnaKarenina[:1000]\n",
    "text3 = AnnaKarenina[:2000]\n",
    "\n",
    "ciphertext1 = text_encoder(text1)\n",
    "ciphertext2 = text_encoder(text2)\n",
    "ciphertext3 = text_encoder(text3)\n",
    "ciphertext4 = text_encoder(AnnaKarenina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d1850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y++@>Y>k@+b.pp.b5.tqpNp.bTVNpbN&b$.Dsfb&p.DqpN3sfbtTD.pTAbZ\"A.b3TZ$3T1Tbp.zNp.q3$%b$3.A-qEb.4TtN&DTDb4t.&TEbA$qb$z.$3ZNAsqb$qD\"NbMTfTLNbVt;1bp.bVt;1.b5.LV.%bpq$z.$3ZNA.%b$qD\"%bpq$z.$3ZNA.bMTb$ATqD;b\\n3Tb5pN1.bTbAqzpsfbgqppT$3%fbTbZiKANbTbAqtqbTb$qD\"qbTbzqZTAqzq$5TDbVT$3TNp$3AqbZqAb3TZ$3TEtTD.pb-NtT5T1TbVsf.pN%bz.$3\"bMqtA.%kbZqAb3TZ$3TEb.pp.b5.tqpNp.btTD.pb-NtT5T1TbVsf.pN%b.pp.b5.tqpNp.bMTt.&NZ.b$TAtqDqppN5TAbA$qVpqApT$3\"ib$TVqtL.pN%bpqTKsz.Ep.%b$ATKTV.bt.$5TA.ppT$3\"bMTAq$3ATA.pN%b;VNAN3qZ\"pTb$Tzq'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciphertext1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffa879",
   "metadata": {},
   "source": [
    "Зашифровали, теперь надо бы получить статистику по корпусу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff74858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_letter_stats(text):\n",
    "    counts = dict(Counter(text))\n",
    "    counts = sorted(counts.items(), key=lambda item: item[1], reverse=True )\n",
    "    counts = [(k, v/len(text)) for k, v in counts]\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d027f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" \" :  0.16759116836318097\n",
      "\"о\" :  0.09513034595302555\n",
      "\"е\" :  0.07242743491488532\n",
      "\"а\" :  0.06859314466860275\n",
      "\"н\" :  0.05748448067215471\n",
      "\"и\" :  0.05498627598220739\n",
      "\"т\" :  0.04957691600291936\n",
      "\"с\" :  0.044003547274936064\n",
      "\"л\" :  0.04153755858919674\n",
      "\"в\" :  0.038988394038047686\n"
     ]
    }
   ],
   "source": [
    "AnnaKarenina_stats = text_letter_stats(AnnaKarenina)\n",
    "show_first_elem(AnnaKarenina_stats, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f745a2",
   "metadata": {},
   "source": [
    "Теперь приступим к расшифровке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86cc6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_decoder(text, global_stats):\n",
    "    \n",
    "    text_count = Counter(text)\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    map_count = {}\n",
    "    for i,value in enumerate(text_count):\n",
    "        map_count[value[0]] = global_stats[i][0]\n",
    "    \n",
    "    \n",
    "    decoded_text = []\n",
    "    \n",
    "    for item in text:\n",
    "        decoded_text.append(map_count[item])\n",
    "    \n",
    "    return \"\".join(decoded_text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed89eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2ee8ъ2ъn8e аееа дарнеиеа омие иб такьж беакнеисьж рокаеол впла совтсояо еагиеанстч тсалхнз аiорибкок iрабоз лтн тгатсвильн тнкпи ыожоши мруя еа мруяа дашмач ентгатсвилач тнкпч ентгатсвила ыо тлонку юсо деияа о лнгеьж щнееотсчж о вэйли о лнрн о тнкпн о гнволнгнтдок мотсоиетслн внл совтсозрокае хиродояо мьжаеич гатсп ынрлачn внл совтсоз аееа дарнеиеа рокае хиродояо мьжаеич аееа дарнеиеа ыорабива толрнкнееидол лтнменлеотспэ томнршаеич енойьгазеач тлойома ратдолаееотсп ыолнтслолаеич умилиснвпео тогнсавитп л юсок рокаен т щнвпеотспэ жумошнтслнееояо лбявчма алсора еа шибеп ое льтсуыав бмнтп дад жумошеид и кьтвиснвп и еабеагнеин итдуттсла лимнв ен л сок гсойь енотыорико рабрнхисп лоырот а л сок гсойь батсалисп вэйисп шибеп л йнтгитвнееьж еидояма ен итсофикьж лтнж нн ырочлвнеичж 1ц цaa ц л sa н яомь омие катсисьз ыитаснвп ыо лимикоку яоегарол тдабав мотсонлтдоку юсо лнфп ентвьжаееач юсо лнфп ынрлач дсо у еат иб ыитаснвнз кошнс ыоралечсптч т юсик а л нлроын дсо ырнмтсалис жосп гсо еийумп ыомойеон 3 i к мотсонлтдиз еажомив л еолок рокаен совтсояо оярокеуэ ытижовояигнтдуэ рабрайосду мухи гнволнгнтдоз тсрахеуэ явуйиеу и тиву и явалеон енйьлавьз мотнвн у еат рнавибк жумошнтслнееояо ибойрашнеич x лрнкч ыомслнрмиво юсу льтодуэ ощнеду иб тсаснз и деия еа лтнж чбьдаж кира ыотлчфнееьж аеен дарнеиеоз кошео тотсалисп щнвуэ йийвиоснду ч йнб довнйаеиз еаблав аееу дарнеиеу лнвигазхик тощиавпеьк рокаеок ло лтнз киролоз виснрасурн l ыитав сокат каее беагнеин рокаеа совтсояо тотсоис ен л ютснсигнтдоз щнееотси осмнвпеьж дарсие а л жумошнтслнееоз балнрхнееотси щнвояо ц лозеу и кир совтсоз еабьлав деияоз о ырохвок л еагавн ц71r яома ое ыротив рнмадсора шуреава руттдиз лнтсеид к е дасдола л оявалвнеии и машн л ойtчлвнеии ен еабьласп няо тогиенеин рокаеок мвч кнеч юсо огнеп лашео и ыосоку огнеп ыроху лат ой юсок 1ц 1s совтсоз коя йь ойотеоласп тлон оырнмнвнеин шаера деияа ттьвдоз еа янянвч досорояо ое леикаснвпео ынрнгисьлав л яомь райось еам лозеоз и кирок янянвп еабьлав деияоз юыигнтдин ыроиблн'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_decoder(ciphertext3, AnnaKarenina_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e098ddf",
   "metadata": {},
   "source": [
    "Собственно прочитать что то осмысленое сложно. попробуем посчитать метрики цифрами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c02679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(true, pred):\n",
    "    return (np.array(list(true)) == np.array(list(pred))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a4204f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy на выборке размером в 500: 0.27\n",
      "Метрика accuracy на выборке размером в 1000: 0.262\n",
      "Метрика accuracy на выборке размером в 2000: 0.425\n"
     ]
    }
   ],
   "source": [
    "metric1 = accuracy_metric(text1, text_decoder(ciphertext1, AnnaKarenina_stats))\n",
    "metric2 = accuracy_metric(text2, text_decoder(ciphertext2, AnnaKarenina_stats))\n",
    "metric3 = accuracy_metric(text3, text_decoder(ciphertext3, AnnaKarenina_stats))\n",
    "\n",
    "print(f'Метрика accuracy на выборке размером в 500: {metric1}')\n",
    "print(f'Метрика accuracy на выборке размером в 1000: {metric2}')\n",
    "print(f'Метрика accuracy на выборке размером в 2000: {metric3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d014227",
   "metadata": {},
   "source": [
    "Метрики тоже не очень"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d26f1",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be03dac2",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c49471e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_maker(text):\n",
    "    bigram_text = []\n",
    "    for i in  range(len(text) - 1):\n",
    "        bigram_text.append(text[i:i+2])\n",
    "    return bigram_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f49dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_bigram_stats(text):\n",
    "    counts = dict(Counter(bigram_maker(text)))\n",
    "    counts = sorted(counts.items(), key=lambda item: item[1], reverse=True )\n",
    "    counts = [(k, v/len(text)) for k, v in counts]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06bda213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina_bigram_stats = text_bigram_stats(AnnaKarenina)\n",
    "len(AnnaKarenina_bigram_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e98e561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an', 'nn', 'no', 'ot', 'ta']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_maker(AnnaKarenina)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7f6995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('о ', 0.023729137208547666),\n",
       " ('е ', 0.018688211168292893),\n",
       " ('а ', 0.01853181711150135),\n",
       " ('и ', 0.017949000308102148),\n",
       " (' н', 0.016254438486761565),\n",
       " (' с', 0.0159967104530976),\n",
       " (' в', 0.014667653843135004),\n",
       " ('то', 0.014148683302620743)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina_bigram_stats[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f9b73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_text_decoder(text, global_bigram_stats):\n",
    "    text_count = Counter(bigram_maker(text))\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True) \n",
    "    map_count = {}\n",
    "    \n",
    "    for number, (text_ngram, text_freq) in enumerate(text_count):\n",
    "        for i, letter in enumerate(text_ngram):\n",
    "            if letter not in map_count and global_bigram_stats[number][0][i] not in map_count.values():\n",
    "                map_count[letter] = global_bigram_stats[number][0][i]\n",
    "                            \n",
    "    decoded_text = []\n",
    "\n",
    "    for item in text:\n",
    "        if item in map_count:\n",
    "            decoded_text.append(map_count[item])\n",
    "        else:\n",
    "            decoded_text.append('*')\n",
    "\n",
    "    return \"\".join(decoded_text)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "297c5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_text_decoder(text, global_bigram_stats, global_stats):\n",
    "    text_count = Counter(bigram_maker(text))\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)\n",
    "      \n",
    "    map_count = {}\n",
    "    used = set()\n",
    "    to_decode = set()    \n",
    "    \n",
    "    \n",
    "    for ecnoded_bigram, _ in text_count:\n",
    "        if ecnoded_bigram[0] in map_count and ecnoded_bigram[1] in map_count:\n",
    "            continue\n",
    "        elif ecnoded_bigram[0] in map_count:\n",
    "            mapped = map_count[ecnoded_bigram[0]]\n",
    "            pos = [\n",
    "                decoded_bigram for decoded_bigram, _ in global_bigram_stats \n",
    "                if decoded_bigram[0] == mapped and \n",
    "                decoded_bigram[1] not in used\n",
    "            ]\n",
    "            if len(pos) > 1:\n",
    "                map_count[ecnoded_bigram[1]] = pos[0][1]\n",
    "                used.add(pos[0][1])\n",
    "            else:\n",
    "                to_decode.add(ecnoded_bigram[1])\n",
    "        elif ecnoded_bigram[1] in map_count:\n",
    "            mapped = map_count[ecnoded_bigram[1]]\n",
    "            pos = [\n",
    "                decoded_bigram for decoded_bigram, _ in global_bigram_stats\n",
    "                if decoded_bigram[1] == mapped and \n",
    "                decoded_bigram[0] not in used\n",
    "            ]\n",
    "            if len(pos) > 1:\n",
    "                map_count[ecnoded_bigram[0]] = pos[0][0]\n",
    "                used.add(pos[0][0])\n",
    "            else:\n",
    "                to_decode.add(ecnoded_bigram[0])\n",
    "        else:\n",
    "            pos = [\n",
    "                decoded_bigram for decoded_bigram, _ in global_bigram_stats \n",
    "                if decoded_bigram[1] not in used and\n",
    "                decoded_bigram[0] not in used\n",
    "            ]\n",
    "            map_count[ecnoded_bigram[0]] = pos[0][0]\n",
    "            map_count[ecnoded_bigram[1]] = pos[0][1]\n",
    "            \n",
    "    text_count = [(var, cnt) for var, cnt in text_count if var in to_decode]\n",
    "    global_stats = [(var, cnt) for var, cnt in global_stats if var not in used]\n",
    "    \n",
    "    for i, (ecnoded_bigram, _) in enumerate(text_count):\n",
    "        map_count[ecnoded_bigram] = global_stats[i][0]\n",
    "    \n",
    "    \n",
    "    decoded_text = []  \n",
    "    \n",
    "    for item in text:\n",
    "        if item in map_count:\n",
    "            decoded_text.append(map_count[item])\n",
    "        else:\n",
    "            decoded_text.append('*')\n",
    "            \n",
    "\n",
    "    return \"\".join(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d66df531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_bigram_text2 = bigram_text_decoder(ciphertext2, AnnaKarenina_bigram_stats, AnnaKarenina_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f949233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1887010878 отто позитото ныот ор оо бы рто ито бы зн отнс лесо  нло ндн тоготои оа о осмия ожнзор н  жзорня сои огоо лосби ои ео вныньо ызйд то ызйдо поьыоа тиогоо лосоа ои еа тиогоо лосо вн осни й к н птодо н сигтбы биттно аы н люусо н сизи н ои еи н гилнсигиопн  ыно ното си лис  нло нязн от мознпндн ыбыотоа гоо е визсоа8 лис  нло ня отто позитото зн от мознпндн ыбыотоа отто позитото внзороло онсзи иттопнс соиытистно ею оныизьотоа тинубгоятоа оснуныо зоопнсоттно е внсио снсотоа йыосо илетн онги олоое с к н  зн оти о билетно ею ыйыньио ситтндн срдлаыо ос нзо то ьорте нт сбо йвол рыиое поп ыйыньтоп о  боло иле о тортогитои оопйоо со соыил ти с  н  г нуб тиновнзо н зорзимо е снвзно о с  н  г нуб роо осо е люуо е ьорте с уиогоолиттбы топндыо ти оо нцо бы соиы ии взнаслитоаы эх хчч х с шч и дныб ныот  оо о бя вооо иле вн соыо н й днтгознс опорол ыно нисопн й к н сице тиолбыоттоа к н сице визсоа п н й тоо ор вооо илия  ньи  внзоста еоа о к о  о с исзнви п н взиыо осо  ын е г н тоуйые внынут'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_bigram_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36f6d6dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.178"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(text2, bigram_text_decoder(ciphertext2, AnnaKarenina_bigram_stats, AnnaKarenina_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8ae7d",
   "metadata": {},
   "source": [
    "Стало только хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c00ec4",
   "metadata": {},
   "source": [
    "## Часть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04410d85",
   "metadata": {},
   "source": [
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "* предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "* реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12309533",
   "metadata": {},
   "source": [
    "Что можно сделать:\n",
    "\n",
    "1. Случайно делаем кодировщик. им восстанавливаем тект и считаем логарифм правдоподобия $p_0$.\n",
    "2. меняем местами случайную пару символов в нем, так же восстанавливаем текст и считаем логарифм правдоподобия.$p_1$ \n",
    "3. с вероятностью $p = \\frac{p_1}{p_0}$ берём новую перестановку.\n",
    "4. Повторяем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2212242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_probability_calc(bigrams, decoder_map, matrix_p, letter_id_dict):\n",
    "    accum  = 0\n",
    "    for bigram, cnt in bigrams:\n",
    "        row = letter_id_dict[decoder_map[bigram[0]]]\n",
    "        col = letter_id_dict[decoder_map[bigram[1]]]\n",
    "        accum += cnt * matrix_p[row, col]\n",
    "    return accum \n",
    "\n",
    "\n",
    "\n",
    "def make_swap(decoder):\n",
    "    d = copy(decoder)\n",
    "    fitst, second  = np.random.choice(np.arange(len(decoder)), size=2, replace=False)\n",
    "    d[fitst], d[second] = d[second], d[fitst]\n",
    "    return d\n",
    "\n",
    "\n",
    "def mcmc_text_decoder(text, map_count):\n",
    "    decoded_text = []\n",
    "    for item in text:\n",
    "        decoded_text.append(map_count[item])\n",
    "    \n",
    "    return \"\".join(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1178f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_map(encoded_text, clear_text, epoch=20, step=20000):\n",
    "    \n",
    "    bigrams_clear = Counter(bigram_maker(clear_text))\n",
    "    bigrams_clear = sorted(bigrams_clear.items(), key=lambda item: item[1], reverse=True) \n",
    "    bigrams_encoded = Counter(bigram_maker(encoded_text))\n",
    "    bigrams_encoded = sorted(bigrams_encoded.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    alphabet_clear = list(set(clear_text))\n",
    "    alphabet_encoded = list(set(encoded_text))\n",
    "    letter_id_dict = {char: i for i, char in enumerate(alphabet_clear)}\n",
    "    \n",
    "    \n",
    "    matrix_p = np.ones((len(alphabet_clear), len(alphabet_clear))) \n",
    "    \n",
    "    for bigram, cnt in bigrams_clear:\n",
    "        row = letter_id_dict[bigram[0]]\n",
    "        col = letter_id_dict[bigram[1]]\n",
    "        matrix_p[row, col] += cnt\n",
    "    \n",
    "    matrix_p /= matrix_p.sum()\n",
    "    matrix_p = np.log(matrix_p)\n",
    "    \n",
    "    probabilities = []\n",
    "    mapps = []\n",
    "    \n",
    "    for _ in tqdm(range(epoch), position=0, total=epoch):\n",
    "        alphabet_clear_copy = copy(alphabet_clear)\n",
    "        decoder_map = dict(zip(alphabet_encoded, alphabet_clear))\n",
    "        p0 = decoder_probability_calc(bigrams_encoded, decoder_map, matrix_p, letter_id_dict)\n",
    "        \n",
    "        for i in range(step):\n",
    "            alphabet_clear_swapped = make_swap(alphabet_clear_copy)\n",
    "            decoder_map_swapped = dict(zip(alphabet_encoded, alphabet_clear_swapped))\n",
    "            p1 = decoder_probability_calc(bigrams_encoded, decoder_map_swapped, matrix_p, letter_id_dict)\n",
    "            if p1 > p0:\n",
    "                alphabet_clear_copy = alphabet_clear_swapped\n",
    "                p0 = p1\n",
    "                decoder_map = decoder_map_swapped\n",
    "            elif np.exp(p1 - p0) > np.random.rand():\n",
    "                alphabet_clear_copy = alphabet_clear_swapped\n",
    "                p0 = p1\n",
    "                decoder_map = decoder_map_swapped        \n",
    "        probabilities.append(p0)\n",
    "        mapps.append(decoder_map)\n",
    "    \n",
    "    \n",
    "    top_idx = np.argmax(probabilities)   \n",
    "    return mapps[top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82a12822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:30<00:00,  4.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:57<00:00,  5.87s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [02:26<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "map1 = mcmc_map(ciphertext1, AnnaKarenina)\n",
    "map2 = mcmc_map(ciphertext2, AnnaKarenina)\n",
    "map3 = mcmc_map(ciphertext3, AnnaKarenina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c99b4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = mcmc_text_decoder(ciphertext1, map1)\n",
    "decoded2 = mcmc_text_decoder(ciphertext2, map2)\n",
    "decoded3 = mcmc_text_decoder(ciphertext3, map3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52a28976",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aiiemamtei анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть перваяt лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях l1 188 1 в 38 е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобн'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9b486d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(text1, decoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93495f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(text2, decoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25402b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(text3, decoded3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df5ad3c",
   "metadata": {},
   "source": [
    "Получился отличный результат!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7ba5f",
   "metadata": {},
   "source": [
    "## Часть 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22f6d1",
   "metadata": {},
   "source": [
    "Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd7d07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d20165a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "message_map = mcmc_map(message, AnnaKarenina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "177cce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_message = mcmc_text_decoder(message, message_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d79c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если ву вимите норкальную или почти норкальную тедст ы этого сообшения доторую легдо прочитать сдорее всего ву все смелали правильно и полычите кадсикальную балл за послемнее четвертое замание дырса хотя донечно я ничего не обешаф'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e40cb",
   "metadata": {},
   "source": [
    "Ура! Получилось! (^_^)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
