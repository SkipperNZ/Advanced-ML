{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a04c0fd",
   "metadata": {},
   "source": [
    "# Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c304315",
   "metadata": {},
   "source": [
    "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются.\n",
    "\n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена.\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам “Война и мир” по-русски и по-английски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67defc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_AnnaKarenina = \"data/AnnaKarenina.txt\"\n",
    "path_to_WarAndPeace = \"data/WarAndPeace.txt\"\n",
    "path_to_WarAndPeaceEng = \"data/WarAndPeaceEng.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095dd10",
   "metadata": {},
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538c084",
   "metadata": {},
   "source": [
    "1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "    * подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "    * возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "    * расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "72dcadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf7ab2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support function\n",
    "\n",
    "def read_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "        data = file.read().replace('\\n', ' ')\n",
    "        data = re.sub('\\W+',' ', data).lower()\n",
    "    return data\n",
    "\n",
    "def show_first_elem(d, i):\n",
    "    cnt = 0\n",
    "    for k, v in d:\n",
    "        cnt+=1\n",
    "        print(f'\\\"{k}\\\" :  {v}')\n",
    "        if cnt == i:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b3691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnnaKarenina = read_data(path_to_AnnaKarenina)\n",
    "WarAndPeace = read_data(path_to_WarAndPeace)\n",
    "WarAndPeaceEng = read_data(path_to_WarAndPeaceEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb401285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annotation   «Анна Каренина», один из самых знаменитых романов Льва Толстого, начинается ставшей афоризмом фразой: «Все счастливые семьи похожи друг н'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2f677",
   "metadata": {},
   "source": [
    "Возьмем из Анны Карениной тестовые тексты это будут 500, 1000 и 2000 первых символов и в качестве бонуса на всем сете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2424d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть перваяi лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях 61 100 1 в 70 е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобн'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ecd53f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encoder(text):\n",
    "    \n",
    "    chars_in_text = list(set(text))\n",
    "    \n",
    "    cipher = list(set(string.printable))\n",
    "    random.shuffle(cipher)\n",
    "    cipher = cipher[:len(chars_in_text)]\n",
    "    mapping = dict(zip(chars_in_text, cipher)) \n",
    "    ciphertext = [mapping[char] for char in text]\n",
    "    \n",
    "    return \"\".join(ciphertext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f25494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = AnnaKarenina[:500]\n",
    "text2 = AnnaKarenina[:1000]\n",
    "text3 = AnnaKarenina[:2000]\n",
    "\n",
    "ciphertext1 = text_encoder(text1)\n",
    "ciphertext2 = text_encoder(text2)\n",
    "ciphertext3 = text_encoder(text3)\n",
    "ciphertext4 = text_encoder(AnnaKarenina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9967b463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"zTT>$z$U>T4y\\x0c\\x0cy4ey%@\\x0cX\\x0cy4<\\tX\\x0c4X{4\\ry'=\\\\4{\\x0cy'@\\x0cX~=\\\\4%<'y\\x0c<?4Im?y4~<I\\r~< <4\\x0cyvX\\x0cy@~\\r,4\\r~y?s@K4yL<%X{'<'4L%y{<K4?\\r@4\\rvy\\r~IX?=@4\\r@'mX4!<\\\\<QX4\\t%F 4\\x0cy4\\t%F y4eyQ\\ty,4\\x0c@\\rvy\\r~IX?y,4\\r@'m,4\\x0c@\\rvy\\r~IX?y4!<4\\r?<@'F4D~<4e\\x0cX y4<4?@v\\x0c=\\\\4;@\\x0c\\x0c<\\r~,\\\\4<4IR*?X4<4?@%@4<4\\r@'m@4<4v@I<?@v@\\re<'4\\t<\\r~<X\\x0c\\r~?@4I@?4~<I\\r~<K%<'y\\x0c4sX%<e< <4\\t=\\\\y\\x0cX,4vy\\r~m4!@%?y,U4I@?4~<I\\r~<K4y\\x0c\\x0cy4ey%@\\x0cX\\x0cy4%<'y\\x0c4sX%<e< <4\\t=\\\\y\\x0cX,4y\\x0c\\x0cy4ey%@\\x0cX\\x0cy4!<%y{XIy4\\r<?%@'@\\x0c\\x0cXe<?4?\\r@\\t\\x0c@?\\x0c<\\r~mR4\\r<\\t@%Qy\\x0cX,4\\x0c@<*=vyK\\x0cy,4\\r?<*<\\ty4%y\\re<?y\\x0c\\x0c<\\r~m4!<?@\\r~?<?y\\x0cX,4F\\tX?X~@Im\\x0c<4\\r<v@\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciphertext1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b378554",
   "metadata": {},
   "source": [
    "Зашифровали, теперь надо бы получить статистику по корпусу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "703a46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_letter_stats(text):\n",
    "    counts = dict(Counter(text))\n",
    "    counts = sorted(counts.items(), key=lambda item: item[1], reverse=True )\n",
    "    counts = [(k, v/len(text)) for k, v in counts]\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c7d61522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" \" :  0.16759116836318097\n",
      "\"о\" :  0.09513034595302555\n",
      "\"е\" :  0.07242743491488532\n",
      "\"а\" :  0.06859314466860275\n",
      "\"н\" :  0.05748448067215471\n",
      "\"и\" :  0.05498627598220739\n",
      "\"т\" :  0.04957691600291936\n",
      "\"с\" :  0.044003547274936064\n",
      "\"л\" :  0.04153755858919674\n",
      "\"в\" :  0.038988394038047686\n"
     ]
    }
   ],
   "source": [
    "AnnaKarenina_stats = text_letter_stats(AnnaKarenina)\n",
    "show_first_elem(AnnaKarenina_stats, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f36d1e",
   "metadata": {},
   "source": [
    "Теперь приступим к расшифровке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1aa8cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_decoder(text, global_stats):\n",
    "    \n",
    "    text_count = Counter(text)\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    map_count = {}\n",
    "    for i,value in enumerate(text_count):\n",
    "        map_count[value[0]] = global_stats[i][0]\n",
    "    \n",
    "    \n",
    "    decoded_text = []\n",
    "    \n",
    "    for item in text:\n",
    "        decoded_text.append(map_count[item])\n",
    "    \n",
    "    return \"\".join(decoded_text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e89015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jojo = text_decoder(ciphertext3, AnnaKarenina_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6efa0720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2ee8ъ2ъn8e аееа дарнеиеа омие иб такьж беакнеисьж рокаеол впла совтсояо еагиеанстч тсалхнз аiорибкок iрабоз лтн тгатсвильн тнкпи ыожоши мруя еа мруяа дашмач ентгатсвилач тнкпч ентгатсвила ыо тлонку юсо деияа о лнгеьж щнееотсчж о вэйли о лнрн о тнкпн о гнволнгнтдок мотсоиетслн внл совтсозрокае хиродояо мьжаеич гатсп ынрлачn внл совтсоз аееа дарнеиеа рокае хиродояо мьжаеич аееа дарнеиеа ыорабива толрнкнееидол лтнменлеотспэ томнршаеич енойьгазеач тлойома ратдолаееотсп ыолнтслолаеич умилиснвпео тогнсавитп л юсок рокаен т щнвпеотспэ жумошнтслнееояо лбявчма алсора еа шибеп ое льтсуыав бмнтп дад жумошеид и кьтвиснвп и еабеагнеин итдуттсла лимнв ен л сок гсойь енотыорико рабрнхисп лоырот а л сок гсойь батсалисп вэйисп шибеп л йнтгитвнееьж еидояма ен итсофикьж лтнж нн ырочлвнеичж 1ц цaa ц л sa н яомь омие катсисьз ыитаснвп ыо лимикоку яоегарол тдабав мотсонлтдоку юсо лнфп ентвьжаееач юсо лнфп ынрлач дсо у еат иб ыитаснвнз кошнс ыоралечсптч т юсик а л нлроын дсо ырнмтсалис жосп гсо еийумп ыомойе'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jojo[:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d491a5c",
   "metadata": {},
   "source": [
    "Собственно прочитать что то осмысленое сложно. попробуем посчитать метрики цифрами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fb09247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(true, pred):\n",
    "    return (np.array(list(true)) == np.array(list(pred))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e317e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy на выборке размером в 500: 0.27\n",
      "Метрика accuracy на выборке размером в 1000: 0.262\n",
      "Метрика accuracy на выборке размером в 2000: 0.425\n"
     ]
    }
   ],
   "source": [
    "metric1 = accuracy_metric(text1, text_decoder(ciphertext1, AnnaKarenina_stats))\n",
    "metric2 = accuracy_metric(text2, text_decoder(ciphertext2, AnnaKarenina_stats))\n",
    "metric3 = accuracy_metric(text3, text_decoder(ciphertext3, AnnaKarenina_stats))\n",
    "\n",
    "print(f'Метрика accuracy на выборке размером в 500: {metric1}')\n",
    "print(f'Метрика accuracy на выборке размером в 1000: {metric2}')\n",
    "print(f'Метрика accuracy на выборке размером в 2000: {metric3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128eb4e",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931246e",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ac2fc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_maker(text):\n",
    "    bigram_text = []\n",
    "    for i in  range(len(text) - 1):\n",
    "        bigram_text.append(text[i:i+2])\n",
    "    return bigram_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ccb6f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_bigram_stats(text):\n",
    "    counts = dict(Counter(bigram_maker(text)))\n",
    "    counts = sorted(counts.items(), key=lambda item: item[1], reverse=True )\n",
    "    counts = [(k, v/len(text)) for k, v in counts]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "67655257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina_bigram_stats = text_bigram_stats(AnnaKarenina)\n",
    "len(AnnaKarenina_bigram_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d65ff5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('о ', 0.023729137208547666),\n",
       " ('е ', 0.018688211168292893),\n",
       " ('а ', 0.01853181711150135),\n",
       " ('и ', 0.017949000308102148),\n",
       " (' н', 0.016254438486761565),\n",
       " (' с', 0.0159967104530976),\n",
       " (' в', 0.014667653843135004),\n",
       " ('то', 0.014148683302620743),\n",
       " (' п', 0.013940157893565352),\n",
       " (' о', 0.013363198545476697)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnaKarenina_bigram_stats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "06997544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_text_decoder(text, global_bigram_stats):\n",
    "    n_gram = 2\n",
    "    text_count = Counter(bigram_maker(text))\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    map_count = {}\n",
    "    \n",
    "    for i, (text_ngram, text_freq) in enumerate(text_count):\n",
    "        global_bigram_stats_copy  = copy(global_bigram_stats)\n",
    "        \n",
    "\n",
    "        for j in range(n_gram):\n",
    "            if text_ngram[j] in map_count:\n",
    "                global_bigram_stats_copy = [\n",
    "                    (ngram, freq)\n",
    "                    for ngram, freq in global_bigram_stats_copy\n",
    "                    if ngram[j] == map_count[text_ngram[j]]\n",
    "                ]\n",
    "\n",
    "        min_diff = 1.0  # maximum possible frequency\n",
    "        best_ngram = None\n",
    "        for ngram, freq in global_bigram_stats_copy:\n",
    "            diff = abs(freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_ngram = ngram\n",
    "                min_diff = diff\n",
    "\n",
    "        for j in range(n_gram):\n",
    "            if text_ngram[j] not in map_count:\n",
    "                map_count[text_ngram[j]] = best_ngram[j]\n",
    "\n",
    "    return map_count\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b0a53102",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3158594432.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [223]\u001b[1;36m\u001b[0m\n\u001b[1;33m    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "text_count = Counter(text)\n",
    "    text_count = sorted(text_count.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "07164788",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [224]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reverse_mapping_bigram \u001b[38;5;241m=\u001b[39m \u001b[43mbigram_text_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mciphertext1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnnaKarenina_bigram_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [222]\u001b[0m, in \u001b[0;36mbigram_text_decoder\u001b[1;34m(text, global_bigram_stats)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_gram):\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m text_ngram[j] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m map_count:\n\u001b[1;32m---> 31\u001b[0m             map_count[text_ngram[j]] \u001b[38;5;241m=\u001b[39m \u001b[43mbest_ngram\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_count\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "reverse_mapping_bigram = bigram_text_decoder(ciphertext1, AnnaKarenina_bigram_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fab9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd7f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2113acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d5b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22577f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcaf28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
